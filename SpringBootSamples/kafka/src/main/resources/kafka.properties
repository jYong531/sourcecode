#用于建立与kafka集群的连接，这个list仅仅影响用于初始化的hosts，来发现全部的servers。
#格式：host1:port1,host2:port2,…，数量尽量不止一个，以防其中一个down了
kafka.producer.servers=localhost:9092
#发生错误时，重传次数。当开启重传时，需要将`max.in.flight.requests.per.connection`设置为1，否则可能导致失序
kafka.producer.retries=3
#Producer可以将发往同一个Partition的数据做成一个Produce Request发送请求，即Batch批处理，以减少请求次数，该值即为每次批处理的大小。
#另外每个Request请求包含多个Batch，每个Batch对应一个Partition，且一个Request发送的目的Broker均为这些partition的leader副本。
#若将该值设为0，则不会进行批处理
kafka.producer.batchsize=0
#当我们获得一个partition的batch.size大小的records，就会立即发送出去，而不管该设置；
#但是如果对于这个partition没有累积到足够的record，会linger指定的时间等待更多的records出现。该设置的默认值为0(无时延)。
#例如，设置linger.ms=5，会减少request发送的数量，但是在无负载下会增加5ms的发送时延。
kafka.producer.lingerms=0
#Producer可以用来缓存数据的内存大小。该值实际为RecordAccumulator类中的BufferPool，即Producer所管理的最大内存。
#如果数据产生速度大于向broker发送的速度，producer会阻塞max.block.ms，超时则抛出异常
kafka.producer.buffermemory=33554432
#控制block的时长，当buffer空间不够或者metadata丢失时产生block
kafka.producer.maxblockms=5000

kafka.consumer.servers=localhost:9092
kafka.consumer.enable.auto.commit=true
kafka.consumer.session.timeout=6000
kafka.consumer.auto.commit.interval=100
kafka.consumer.auto.offset.reset=latest
kafka.consumer.topic=mytopic
kafka.consumer.group.id=com.group.id-01


